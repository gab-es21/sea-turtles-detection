{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: albumentations in c:\\users\\gaby3\\documents\\sea-turtles-detection\\.venv\\lib\\site-packages (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.11.1 in c:\\users\\gaby3\\documents\\sea-turtles-detection\\.venv\\lib\\site-packages (from albumentations) (1.26.1)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\gaby3\\documents\\sea-turtles-detection\\.venv\\lib\\site-packages (from albumentations) (1.11.3)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in c:\\users\\gaby3\\documents\\sea-turtles-detection\\.venv\\lib\\site-packages (from albumentations) (0.22.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\gaby3\\documents\\sea-turtles-detection\\.venv\\lib\\site-packages (from albumentations) (6.0.1)\n",
      "Requirement already satisfied: qudida>=0.0.4 in c:\\users\\gaby3\\documents\\sea-turtles-detection\\.venv\\lib\\site-packages (from albumentations) (0.0.4)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in c:\\users\\gaby3\\documents\\sea-turtles-detection\\.venv\\lib\\site-packages (from albumentations) (4.8.0.74)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in c:\\users\\gaby3\\documents\\sea-turtles-detection\\.venv\\lib\\site-packages (from qudida>=0.0.4->albumentations) (1.3.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\gaby3\\documents\\sea-turtles-detection\\.venv\\lib\\site-packages (from qudida>=0.0.4->albumentations) (4.8.0)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\gaby3\\documents\\sea-turtles-detection\\.venv\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (3.2.1)\n",
      "Requirement already satisfied: pillow>=9.0.1 in c:\\users\\gaby3\\documents\\sea-turtles-detection\\.venv\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (10.1.0)\n",
      "Requirement already satisfied: imageio>=2.27 in c:\\users\\gaby3\\documents\\sea-turtles-detection\\.venv\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (2.33.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\gaby3\\documents\\sea-turtles-detection\\.venv\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (2023.9.26)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\gaby3\\documents\\sea-turtles-detection\\.venv\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (23.2)\n",
      "Requirement already satisfied: lazy_loader>=0.3 in c:\\users\\gaby3\\documents\\sea-turtles-detection\\.venv\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (0.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\gaby3\\documents\\sea-turtles-detection\\.venv\\lib\\site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\gaby3\\documents\\sea-turtles-detection\\.venv\\lib\\site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.2.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\gaby3\\documents\\sea-turtles-detection\\.venv\\lib\\site-packages (4.8.1.78)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\gaby3\\documents\\sea-turtles-detection\\.venv\\lib\\site-packages (from opencv-python) (1.26.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\gaby3\\documents\\sea-turtles-detection\\.venv\\lib\\site-packages (0.16.0+cu121)\n",
      "Requirement already satisfied: numpy in c:\\users\\gaby3\\documents\\sea-turtles-detection\\.venv\\lib\\site-packages (from torchvision) (1.26.1)\n",
      "Requirement already satisfied: requests in c:\\users\\gaby3\\documents\\sea-turtles-detection\\.venv\\lib\\site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: torch==2.1.0+cu121 in c:\\users\\gaby3\\documents\\sea-turtles-detection\\.venv\\lib\\site-packages (from torchvision) (2.1.0+cu121)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\gaby3\\documents\\sea-turtles-detection\\.venv\\lib\\site-packages (from torchvision) (10.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\gaby3\\documents\\sea-turtles-detection\\.venv\\lib\\site-packages (from torch==2.1.0+cu121->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\gaby3\\documents\\sea-turtles-detection\\.venv\\lib\\site-packages (from torch==2.1.0+cu121->torchvision) (4.8.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\gaby3\\documents\\sea-turtles-detection\\.venv\\lib\\site-packages (from torch==2.1.0+cu121->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\gaby3\\documents\\sea-turtles-detection\\.venv\\lib\\site-packages (from torch==2.1.0+cu121->torchvision) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\gaby3\\documents\\sea-turtles-detection\\.venv\\lib\\site-packages (from torch==2.1.0+cu121->torchvision) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\gaby3\\documents\\sea-turtles-detection\\.venv\\lib\\site-packages (from torch==2.1.0+cu121->torchvision) (2023.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gaby3\\documents\\sea-turtles-detection\\.venv\\lib\\site-packages (from requests->torchvision) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gaby3\\documents\\sea-turtles-detection\\.venv\\lib\\site-packages (from requests->torchvision) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gaby3\\documents\\sea-turtles-detection\\.venv\\lib\\site-packages (from requests->torchvision) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gaby3\\documents\\sea-turtles-detection\\.venv\\lib\\site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\gaby3\\documents\\sea-turtles-detection\\.venv\\lib\\site-packages (from jinja2->torch==2.1.0+cu121->torchvision) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\gaby3\\documents\\sea-turtles-detection\\.venv\\lib\\site-packages (from sympy->torch==2.1.0+cu121->torchvision) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U albumentations\n",
    "!pip install opencv-python\n",
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torch\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to your dataset\n",
    "dataset_path = \"./sea-turtles-1-test/all/images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a set of augmentations\n",
    "transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    A.RandomCrop(224, 224),\n",
    "    A.HorizontalFlip(),\n",
    "    A.Rotate(limit=30),\n",
    "    A.RandomBrightnessContrast(),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Couldn't find any class folder in ./sea-turtles-1-test/all/images/.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\gaby3\\Documents\\sea-turtles-detection\\data_augmentation\\augmentaion.ipynb Cell 5\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gaby3/Documents/sea-turtles-detection/data_augmentation/augmentaion.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Use torchvision's ImageFolder to load the dataset\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gaby3/Documents/sea-turtles-detection/data_augmentation/augmentaion.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# ImageFolder assumes the dataset is organized with subfolders for each class\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gaby3/Documents/sea-turtles-detection/data_augmentation/augmentaion.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# and each image in its respective class folder.\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/gaby3/Documents/sea-turtles-detection/data_augmentation/augmentaion.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m dataset \u001b[39m=\u001b[39m datasets\u001b[39m.\u001b[39;49mImageFolder(root\u001b[39m=\u001b[39;49mdataset_path, transform\u001b[39m=\u001b[39;49mtransform)\n",
      "File \u001b[1;32mc:\\Users\\gaby3\\Documents\\sea-turtles-detection\\.venv\\Lib\\site-packages\\torchvision\\datasets\\folder.py:309\u001b[0m, in \u001b[0;36mImageFolder.__init__\u001b[1;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m    302\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    303\u001b[0m     root: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    307\u001b[0m     is_valid_file: Optional[Callable[[\u001b[39mstr\u001b[39m], \u001b[39mbool\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    308\u001b[0m ):\n\u001b[1;32m--> 309\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[0;32m    310\u001b[0m         root,\n\u001b[0;32m    311\u001b[0m         loader,\n\u001b[0;32m    312\u001b[0m         IMG_EXTENSIONS \u001b[39mif\u001b[39;49;00m is_valid_file \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    313\u001b[0m         transform\u001b[39m=\u001b[39;49mtransform,\n\u001b[0;32m    314\u001b[0m         target_transform\u001b[39m=\u001b[39;49mtarget_transform,\n\u001b[0;32m    315\u001b[0m         is_valid_file\u001b[39m=\u001b[39;49mis_valid_file,\n\u001b[0;32m    316\u001b[0m     )\n\u001b[0;32m    317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimgs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msamples\n",
      "File \u001b[1;32mc:\\Users\\gaby3\\Documents\\sea-turtles-detection\\.venv\\Lib\\site-packages\\torchvision\\datasets\\folder.py:144\u001b[0m, in \u001b[0;36mDatasetFolder.__init__\u001b[1;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m    135\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    136\u001b[0m     root: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    141\u001b[0m     is_valid_file: Optional[Callable[[\u001b[39mstr\u001b[39m], \u001b[39mbool\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    142\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(root, transform\u001b[39m=\u001b[39mtransform, target_transform\u001b[39m=\u001b[39mtarget_transform)\n\u001b[1;32m--> 144\u001b[0m     classes, class_to_idx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfind_classes(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroot)\n\u001b[0;32m    145\u001b[0m     samples \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_dataset(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot, class_to_idx, extensions, is_valid_file)\n\u001b[0;32m    147\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader \u001b[39m=\u001b[39m loader\n",
      "File \u001b[1;32mc:\\Users\\gaby3\\Documents\\sea-turtles-detection\\.venv\\Lib\\site-packages\\torchvision\\datasets\\folder.py:218\u001b[0m, in \u001b[0;36mDatasetFolder.find_classes\u001b[1;34m(self, directory)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfind_classes\u001b[39m(\u001b[39mself\u001b[39m, directory: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[List[\u001b[39mstr\u001b[39m], Dict[\u001b[39mstr\u001b[39m, \u001b[39mint\u001b[39m]]:\n\u001b[0;32m    192\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Find the class folders in a dataset structured as follows::\u001b[39;00m\n\u001b[0;32m    193\u001b[0m \n\u001b[0;32m    194\u001b[0m \u001b[39m        directory/\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[39m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 218\u001b[0m     \u001b[39mreturn\u001b[39;00m find_classes(directory)\n",
      "File \u001b[1;32mc:\\Users\\gaby3\\Documents\\sea-turtles-detection\\.venv\\Lib\\site-packages\\torchvision\\datasets\\folder.py:42\u001b[0m, in \u001b[0;36mfind_classes\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     40\u001b[0m classes \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(entry\u001b[39m.\u001b[39mname \u001b[39mfor\u001b[39;00m entry \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mscandir(directory) \u001b[39mif\u001b[39;00m entry\u001b[39m.\u001b[39mis_dir())\n\u001b[0;32m     41\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m classes:\n\u001b[1;32m---> 42\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find any class folder in \u001b[39m\u001b[39m{\u001b[39;00mdirectory\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     44\u001b[0m class_to_idx \u001b[39m=\u001b[39m {cls_name: i \u001b[39mfor\u001b[39;00m i, cls_name \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(classes)}\n\u001b[0;32m     45\u001b[0m \u001b[39mreturn\u001b[39;00m classes, class_to_idx\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Couldn't find any class folder in ./sea-turtles-1-test/all/images/."
     ]
    }
   ],
   "source": [
    "# Use torchvision's ImageFolder to load the dataset\n",
    "# ImageFolder assumes the dataset is organized with subfolders for each class\n",
    "# and each image in its respective class folder.\n",
    "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\gaby3\\Documents\\sea-turtles-detection\\data_augmentation\\augmentaion.ipynb Cell 6\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gaby3/Documents/sea-turtles-detection/data_augmentation/augmentaion.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Create a DataLoader to efficiently load and batch the data during training\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gaby3/Documents/sea-turtles-detection/data_augmentation/augmentaion.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m32\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/gaby3/Documents/sea-turtles-detection/data_augmentation/augmentaion.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m data_loader \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(dataset, batch_size\u001b[39m=\u001b[39mbatch_size, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gaby3/Documents/sea-turtles-detection/data_augmentation/augmentaion.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Accessing dataset labels\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gaby3/Documents/sea-turtles-detection/data_augmentation/augmentaion.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m class_labels \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mclasses\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a DataLoader to efficiently load and batch the data during training\n",
    "batch_size = 32\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Accessing dataset labels\n",
    "class_labels = dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 5, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\gaby3\\Documents\\sea-turtles-detection\\data_augmentation\\augmentaion.ipynb Cell 7\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gaby3/Documents/sea-turtles-detection/data_augmentation/augmentaion.ipynb#X13sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     annotation \u001b[39m=\u001b[39m [\u001b[39mfloat\u001b[39m(coord) \u001b[39mfor\u001b[39;00m coord \u001b[39min\u001b[39;00m f\u001b[39m.\u001b[39mreadline()\u001b[39m.\u001b[39mstrip()\u001b[39m.\u001b[39msplit()]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gaby3/Documents/sea-turtles-detection/data_augmentation/augmentaion.ipynb#X13sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m# Extract the bounding box coordinates\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/gaby3/Documents/sea-turtles-detection/data_augmentation/augmentaion.ipynb#X13sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m class_label, xmin, ymin, xmax, ymax \u001b[39m=\u001b[39m annotation\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gaby3/Documents/sea-turtles-detection/data_augmentation/augmentaion.ipynb#X13sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m# Apply the augmentation to the image and bounding box\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gaby3/Documents/sea-turtles-detection/data_augmentation/augmentaion.ipynb#X13sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m augmented \u001b[39m=\u001b[39m transform(image\u001b[39m=\u001b[39mimage, bboxes\u001b[39m=\u001b[39m[[xmin, ymin, xmax, ymax]], class_labels\u001b[39m=\u001b[39m[class_label])\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 5, got 0)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# Define paths to the image and annotation directories\n",
    "image_dir = \"./sea-turtles-1-test/all/images/\"\n",
    "annotation_dir = \"./sea-turtles-1-test/all/labels/\"\n",
    "\n",
    "# Define the transformation pipeline including image and bounding box augmentations\n",
    "transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    A.RandomCrop(224, 224),\n",
    "    A.HorizontalFlip(),\n",
    "    A.Rotate(limit=30),\n",
    "    A.RandomBrightnessContrast(),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['class_labels']))\n",
    "\n",
    "# Get the list of image files\n",
    "image_files = os.listdir(image_dir)\n",
    "\n",
    "# Iterate through each image\n",
    "for image_file in image_files:\n",
    "    # Load the image\n",
    "    image_path = os.path.join(image_dir, image_file)\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Load the corresponding annotation file\n",
    "    annotation_file = os.path.join(annotation_dir, image_file.replace('.jpg', '.txt'))\n",
    "    with open(annotation_file, 'r') as f:\n",
    "        # Assuming each line of the annotation file contains [class, xmin, ymin, xmax, ymax]\n",
    "        annotation = [float(coord) for coord in f.readline().strip().split()]\n",
    "\n",
    "    # Extract the bounding box coordinates\n",
    "    class_label, xmin, ymin, xmax, ymax = annotation\n",
    "\n",
    "    # Apply the augmentation to the image and bounding box\n",
    "    augmented = transform(image=image, bboxes=[[xmin, ymin, xmax, ymax]], class_labels=[class_label])\n",
    "\n",
    "    # Extract the augmented image and bounding box\n",
    "    augmented_image = augmented['image']\n",
    "    augmented_bbox = augmented['bboxes'][0]\n",
    "\n",
    "    # Update the annotation file with the new bounding box coordinates\n",
    "    with open(annotation_file, 'w') as f:\n",
    "        f.write(f\"{class_label} {augmented_bbox[0]} {augmented_bbox[1]} {augmented_bbox[2]} {augmented_bbox[3]}\")\n",
    "\n",
    "    # Save the augmented image\n",
    "    augmented_image_path = os.path.join(\"./sea-turtles-1-test/all/augmented_images/\", image_file)\n",
    "    cv2.imwrite(augmented_image_path, cv2.cvtColor(augmented_image, cv2.COLOR_RGB2BGR))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
